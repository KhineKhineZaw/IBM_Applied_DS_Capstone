{"cells": [{"metadata": {}, "cell_type": "code", "source": "#importing necessary libraries\nimport requests\nimport pandas as pd", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#scrapping neighborhoods in Canada\nurl  = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\npage = requests.get(url)\nif page.status_code == 200:\n    print('Page download successful')\nelse:\n    print('Page download error. Error code: {}'.format(page.status_code))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_html = pd.read_html(url, header=0, na_values = ['Not assigned'])[0]\ndf_html.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Drop the the rows on which the Borough is empty\ndf_html.dropna(subset=['Borough'], inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Check Neighborhood is empty but Borough exists\nn_empty_neighborhood = df_html[df_html['Neighbourhood'].isna()].shape[0]\nprint('Number of rows on which Neighborhood column is empty: {}'.format(n_empty_neighborhood))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Show which neighborhood is emtpy but Borough exists\ndf_html[df_html['Neighbourhood'].isna()]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Replace empty Neighborhood with Borough name and check again\ndf_html['Neighbourhood'].fillna(df_html['Borough'], inplace=True)\nn_empty_neighborhood = df_html[df_html['Neighbourhood'].isna()].shape[0]\nprint('Number of rows on which Neighborhood column is empty: {}'.format(n_empty_neighborhood))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Confirm that Queen's Park Neighborhood is not empty now:\ndf_html[df_html['Borough']==\"Queen's Park\"]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Group by Postcode / Borough\ndf_postcodes = df_html.groupby(['Postal code','Borough']).Neighbourhood.agg([('Neighbourhood', ', '.join)])\ndf_postcodes.reset_index(inplace=True)\ndf_postcodes.head(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Drop the the rows on which the Borough is empty\ndf_html.dropna(subset=['Borough'], inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Check Neighborhood is empty but Borough exists\nn_empty_neighborhood = df_html[df_html['Neighbourhood'].isna()].shape[0]\nprint('Number of rows on which Neighborhood column is empty: {}'.format(n_empty_neighborhood))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('The shape of the dataset is:',df_postcodes.shape)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#to make it easier, we will store this in csv format.\n#Export to .CSV\ndf_postcodes.to_csv('Toronto_Postcodes.csv')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Read CSV file from link and load into dataframe\nurl_csv = 'http://cocl.us/Geospatial_data'\ndf_coordinates = pd.read_csv(url_csv)\ndf_coordinates.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#use the previously cleaned data\ndf_neighborhoods = pd.read_csv('Toronto_Postcodes.csv',index_col=[0])\ndf_neighborhoods.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Make sure both dataframes have the same \ndf_coordinates.rename(columns={'Postal Code': 'PostalCode'}, inplace=True)\ndf_neighborhoods.rename(columns={'Postcode': 'PostalCode'}, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Merge both datasets\ndf_neighborhoods_coordinates = pd.merge(df_neighborhoods, df_coordinates, on='PostalCode')\ndf_neighborhoods_coordinates.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Check coordinates for a couple of neighborhoods\ndf_neighborhoods_coordinates[(df_neighborhoods_coordinates['PostalCode']=='M5G') |\n                             (df_neighborhoods_coordinates['PostalCode']=='M2H') ]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Export to .CSV\ndf_neighborhoods_coordinates.to_csv('Toronto_Postcodes_2.csv')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import folium\nfrom sklearn.cluster import KMeans", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Read .csv file from above\ndf = pd.read_csv('Toronto_Postcodes_2.csv', index_col=0)\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('The dataframe has {} boroughs and {} neighborhoods.'.format(\n        len(df['Borough'].unique()),\n        df.shape[0]\n    )\n)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df.rename(columns={'Neighbourhood': 'Neighborhood'}, inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#count Bourough and Neighborhood\ndf.groupby('Borough').count()['Neighborhood']", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_toronto = df[df['Borough'].str.contains('Toronto')]\ndf_toronto.reset_index(inplace=True)\ndf_toronto.drop('index', axis=1, inplace=True)\ndf_toronto.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Check the number of neighborhoods\nprint(df_toronto.groupby('Borough').count()['Neighborhood'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Create list with the Boroughs (to be used later)\nboroughs = df_toronto['Borough'].unique().tolist()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Obtain the coordinates from the dataset itself, just averaging Latitude/Longitude of the current dataset \nlat_toronto = df_toronto['Latitude'].mean()\nlon_toronto = df_toronto['Longitude'].mean()\nprint('The geographical coordinates of Toronto are {}, {}'.format(lat_toronto, lon_toronto))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "borough_color = {}\nfor borough in boroughs:\n    borough_color[borough]= '#%02X%02X%02X' % tuple(np.random.choice(range(256), size=3)) #Random color", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "map_toronto = folium.Map(location=[lat_toronto, lon_toronto], zoom_start=12)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(df_toronto['Latitude'], \n                                           df_toronto['Longitude'],\n                                           df_toronto['Borough'], \n                                           df_toronto['Neighborhood']):\n    label_text = borough + ' - ' + neighborhood\n    label = folium.Popup(label_text)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color=borough_color[borough],\n        fill_color=borough_color[borough],\n        fill_opacity=0.7).add_to(map_toronto)  \n    \nmap_toronto", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "CLIENT_ID = '' # your Foursquare ID\nCLIENT_SECRET = '' # your Foursquare Secret\nVERSION = '' # Foursquare API version\nLIMIT = 100 # limit of number of venues returned by Foursquare API\nradius = 500 # define radius", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Get venues for all neighborhoods in our dataset\ntoronto_venues = getNearbyVenues(names=df_toronto['Neighborhood'],\n                                latitudes=df_toronto['Latitude'],\n                                longitudes=df_toronto['Longitude'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Check size of resulting dataframe\ntoronto_venues.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "toronto_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Number of venues per neighborhood\ntoronto_venues.groupby('Neighborhood').count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Number of unique venue categories\nprint('There are {} uniques categories.'.format(len(toronto_venues['Venue Category'].unique())))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#print out the list of categories\ntoronto_venues['Venue Category'].unique()[:100]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# check if the results contain \"Thai Restaurants\"\n#please note I changed the data to Thai because I was previously writing the code using Asian but the number is so small\n\"Thai Restaurant\" in toronto_venues['Venue Category'].unique()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# one hot encoding\nto_onehot = pd.get_dummies(toronto_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nto_onehot['Neighborhoods'] = toronto_venues['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [to_onehot.columns[-1]] + list(to_onehot.columns[:-1])\nto_onehot = to_onehot[fixed_columns]\n\nprint(to_onehot.shape)\nto_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "to_grouped = to_onehot.groupby([\"Neighborhoods\"]).mean().reset_index()\n\nprint(to_grouped.shape)\nto_grouped", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "to_asian = to_grouped[[\"Neighborhoods\",\"Thai Restaurant\"]]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "to_asian.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# set number of clusters\ntoclusters = 3\n\nto_clustering = to_asian.drop([\"Neighborhoods\"], 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=toclusters, random_state=0).fit(to_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# create a new dataframe that includes the cluster as well as the top 10 venues for each neighborhood.\nto_merged = to_asian.copy()\n\n# add clustering labels\nto_merged[\"Cluster Labels\"] = kmeans.labels_", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "to_merged.rename(columns={\"Neighborhoods\": \"Neighborhood\"}, inplace=True)\nto_merged.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nto_merged = to_merged.join(toronto_venues.set_index(\"Neighborhood\"), on=\"Neighborhood\")\n\nprint(to_merged.shape)\nto_merged.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# sort the results by Cluster Labels\nprint(to_merged.shape)\nto_merged.sort_values([\"Cluster Labels\"], inplace=True)\nto_merged", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# create map\nmap_clusters = folium.Map(location=[lat_toronto, lon_toronto], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(toclusters)\nys = [i+x+(i*x)**2 for i in range(toclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(to_merged['Neighborhood Latitude'], to_merged['Neighborhood Longitude'], to_merged['Neighborhood'], to_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' - Cluster ' + str(cluster))\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# save the map as HTML file\nmap_clusters.save('map_clusters.html')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n#Cluster 0\nto_merged.loc[to_merged['Cluster Labels'] == 0]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n#Cluster 1\nto_merged.loc[to_merged['Cluster Labels'] == 1]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Cluster 2\nto_merged.loc[to_merged['Cluster Labels'] == 2]\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}